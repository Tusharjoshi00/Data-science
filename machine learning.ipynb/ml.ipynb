{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7cfe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#machine learning life cycle\n",
    "# 1.gathering data-----> 2.data preparation---> 3.data wragling-----> 4.analyse data---->5.train model\n",
    "# ------>6.test model -----> 7.deployment\n",
    "\n",
    "### problem definition----> data dollection---- data cleaning-----eda\n",
    "\n",
    "## y= mx + c\n",
    "#y = Dependent vairable\n",
    "#m =slope\n",
    "#x= independent variable\n",
    "#c=intersept \n",
    " \n",
    "#y = m1x1 + m2x2 + m3x3 +...........+MnXn + C \n",
    "# the main goal of linear regresion is to find best optimal values of C and M\n",
    "#best fit line(bfl)----least error----> actual point and predictate point diff is very low\n",
    "\n",
    "##loss function ---error--- single \n",
    "## cost function -----error ---- whole ----avg error of whole \n",
    "\n",
    "# Model Evaluation (Reg)\n",
    "# R² , RMSE   adjusted Rsq\n",
    "## R2 ------> Variation    / variation ka mtlb hoga hoga actual data ka avg kitna differe krta hai   \n",
    "# example of variation : marks =[70,75,80,85,90]\n",
    "#                          avg =80 ----> (70-80)² =20   \n",
    "#     Range ---  0 to 1\n",
    "#    R²  ---->  jitna 1 ke pass R(sq) ki value utna acha hai\n",
    "#   R² = 1-(RSS/Tss) => 1 -(RSS=MSE)/submision(yi-y^)² RSS =residual sum of sq ,,  TSS = toal sum of sq\n",
    "### RSS = MSE\n",
    "#drawbacks of Rsq is they don't show the correlation of the independent coloumn\n",
    "\n",
    "## RMSE =sq.root(MSE)= how close the observed value to the predicted value\n",
    "## MAE -- mean absolute error\n",
    "## MSE(mean square error) --> it do not deals with outliers(exceptions)\n",
    "## MAE(mean absolute error) ---> deals with outliers\n",
    "## Adjusted R² ----it increases the accuracy\n",
    "## adjusted R(sq.)= 1 - (1-r²)(N-1)/ N-P-1       n=total points , p= no of independent features\n",
    "## Huber Loss -- cpmbination of MSE & MAE\n",
    "\n",
    "#revsion \n",
    "#linear regression\n",
    "# realtionship b/w x & y\n",
    "# best fit straight line ----> kosis krti hai jyada se jayda data point cover kr paye ya lie kre\n",
    "# graph 1. positive , 2. negative\n",
    "#simple linear equation ---> ek x point hoga ek hoga y point --> y=m1x1+...MnXn+ error\n",
    "#best fit line hogi konsi -> jo slope(m) & intersept(c)---> optimsl value dega\n",
    "##cost function--> loss calculate krta hai ---> m & c\n",
    "\n",
    "\n",
    "##classificTION---->CM,PRE\n",
    "##REGRESSION----> MSE"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
