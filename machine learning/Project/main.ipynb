{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "75da9053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle , joblib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "92967518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "x,y=[],[]\n",
    "with open (\"SMSSpamcollection.txt\",\"r\") as file:\n",
    "    data=file.read()\n",
    "    #iterate through each line\n",
    "    for data_item in data.split(\"\\n\"):\n",
    "#it will check if the line cinatins exactly 2 elements separated by a tab\n",
    "        if len(data_item.split(\"\\t\"))==2:\n",
    "            #append the first element (label) to y\n",
    "            y.append(data_item.split(\"\\t\")[0])\n",
    "            #append the second element (text) to x\n",
    "            x.append(data_item.split(\"\\t\")[1])\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9dd1e61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10574, 10574)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x),len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "23cdfbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mail_message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        mail_message label\n",
       "0  Go until jurong point, crazy.. Available only ...   ham\n",
       "1                      Ok lar... Joking wif u oni...   ham\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
       "3  U dun say so early hor... U c already then say...   ham\n",
       "4  Nah I don't think he goes to usf, he lives aro...   ham"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## preo your data\n",
    "data_dict = {\"mail_message\":x,\"label\":y}\n",
    "df=pd.DataFrame(data_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "730fd277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10574 entries, 0 to 10573\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   mail_message  10574 non-null  object\n",
      " 1   label         10574 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 165.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6189608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mail_message    0\n",
       "label           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "67d91a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_8864\\2861600116.py:4: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"mail_message\"][i]=message\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mail_message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go until jurong point  crazy   available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar    joking wif u oni</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry in   a wkly comp to win fa cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u dun say so early hor    u c already then say</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah i don t think he goes to usf  he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        mail_message label\n",
       "0  go until jurong point  crazy   available only ...   ham\n",
       "1                      ok lar    joking wif u oni      ham\n",
       "2  free entry in   a wkly comp to win fa cup fina...  spam\n",
       "3  u dun say so early hor    u c already then say      ham\n",
       "4  nah i don t think he goes to usf  he lives aro...   ham"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,len(df)):\n",
    "    message =re.sub(\"[^a-zA-Z]\",\" \",df[\"mail_message\"][i])\n",
    "    message = message.lower()\n",
    "    df[\"mail_message\"][i]=message\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2ca83e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "spam    5747\n",
       "ham     4827\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9879631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     4827\n",
       "spam    4827\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##filter\n",
    "ham=df[df[\"label\"]==\"ham\"]\n",
    "spam=df[df[\"label\"]==\"spam\"].sample(n=4827)\n",
    "df=pd.concat([ham,spam],axis=0)\n",
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f236e103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mail_message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go until jurong point  crazy   available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar    joking wif u oni</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u dun say so early hor    u c already then say</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah i don t think he goes to usf  he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>even my brother is not like to speak with me  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        mail_message  label\n",
       "0  go until jurong point  crazy   available only ...      0\n",
       "1                      ok lar    joking wif u oni         0\n",
       "3  u dun say so early hor    u c already then say         0\n",
       "4  nah i don t think he goes to usf  he lives aro...      0\n",
       "6  even my brother is not like to speak with me  ...      0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"]=df[\"label\"].map({\"ham\":0,\"spam\":1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b322a1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3675)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "012834df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## x and y\n",
    "x = df[\"mail_message\"]\n",
    "y=df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e24f500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare the single list of mails\n",
    "x = x.values\n",
    "y=y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b955ed8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['go until jurong point  crazy   available only in bugis n great world la e buffet    cine there got amore wat   ',\n",
       "       'ok lar    joking wif u oni   ',\n",
       "       'u dun say so early hor    u c already then say   ',\n",
       "       'nah i don t think he goes to usf  he lives around here though',\n",
       "       'even my brother is not like to speak with me  they treat me like aids patent '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a315611c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      3\u001b[39m Bow_obj = CountVectorizer(\n\u001b[32m      4\u001b[39m     max_features=\u001b[32m2000\u001b[39m,\n\u001b[32m      5\u001b[39m     stop_words=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m## to array ---> sparse matrix ---> dense matrix\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m x=\u001b[43mBow_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m.toarray\n\u001b[32m     10\u001b[39m x.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1376\u001b[39m, in \u001b[36mCountVectorizer.fit_transform\u001b[39m\u001b[34m(self, raw_documents, y)\u001b[39m\n\u001b[32m   1368\u001b[39m             warnings.warn(\n\u001b[32m   1369\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mUpper case characters found in\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1370\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m vocabulary while \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlowercase\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1371\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m is True. These entries will not\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1372\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m be matched with any documents\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1373\u001b[39m             )\n\u001b[32m   1374\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1376\u001b[39m vocabulary, X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.binary:\n\u001b[32m   1379\u001b[39m     X.data.fill(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1263\u001b[39m, in \u001b[36mCountVectorizer._count_vocab\u001b[39m\u001b[34m(self, raw_documents, fixed_vocab)\u001b[39m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[32m   1262\u001b[39m     feature_counter = {}\n\u001b[32m-> \u001b[39m\u001b[32m1263\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1264\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1265\u001b[39m             feature_idx = vocabulary[feature]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:104\u001b[39m, in \u001b[36m_analyze\u001b[39m\u001b[34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m         doc = \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    106\u001b[39m         doc = tokenizer(doc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:62\u001b[39m, in \u001b[36m_preprocess\u001b[39m\u001b[34m(doc, accent_function, lower)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[33;03mapply to a document.\u001b[39;00m\n\u001b[32m     45\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m \u001b[33;03m    preprocessed string\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     doc = \u001b[43mdoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m()\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m accent_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     64\u001b[39m     doc = accent_function(doc)\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# because in ml algorithm data is used in form of mathematical from so we typecast data in array\n",
    "## bag of words \n",
    "Bow_obj = CountVectorizer(\n",
    "    max_features=2000,\n",
    "    stop_words=\"english\"\n",
    "\n",
    ")\n",
    "## to array ---> sparse matrix ---> dense matrix\n",
    "x=Bow_obj.fit_transform(x).toarray\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f3b83875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CountVectorizer.lb']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(Bow_obj,\"CountVectorizer.lb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0354f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(\n",
    "    x_transformed , y,\n",
    "    test_size=0.2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
